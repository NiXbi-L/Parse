```markdown
# Веб-скрапер с использованием Playwright и BeautifulSoup

Этот проект представляет собой веб-скрапер, который использует Playwright для автоматизации браузера и BeautifulSoup для парсинга HTML. Он предназначен для извлечения контента, ссылок и метаданных с веб-страниц и сохранения результатов в формате JSON. Кроме того, программа может загружать PDF-файлы, ссылки на которые найдены на страницах.

## Возможности

- **Извлечение HTML-контента**: Извлекает текстовый контент из параграфов (`<p>`) и элементов списка (`<li>`) на веб-страницах.
- **Извлечение ссылок**: Собирает все абсолютные ссылки на странице, исключая ссылки на социальные сети, такие как Twitter, YouTube и Facebook.
- **Загрузка PDF**: Автоматически загружает PDF-файлы, ссылки на которые найдены на странице.
- **Сохранение в JSON**: Сохраняет извлеченные данные в структурированном формате JSON.
- **Автоматизация браузера**: Использует Playwright для обработки контента, который отображается с помощью JavaScript.

## Требования

- Python 3.7+
- Playwright
- BeautifulSoup
- Requests

## Установка

1. **Клонируйте репозиторий**:
   ```bash
   git clone https://github.com/yourusername/web-scraper.git
   cd web-scraper
   ```

2. **Установите зависимости**:
   ```bash
   pip install playwright beautifulsoup4 requests
   ```

3. **Установите браузеры для Playwright**:
   ```bash
   playwright install
   ```

## Использование

Для запуска скрапера используйте следующую команду:

```bash
python main.py <url> <имя_файла>
```

- `<url>`: URL веб-страницы, которую вы хотите обработать.
- `<имя_файла>`: Имя выходного JSON-файла (без расширения `.json`).

### Пример

```bash
python main.py https://example.com example_output
```

Это создаст JSON-файл с именем `example_output.json` в директории `jsons`, содержащий извлеченные данные.

## Структура выходного файла

Выходной JSON-файл будет иметь следующую структуру:

```json
{
    "title": "Заголовок страницы",
    "publish_time": null,
    "source_url": "https://example.com",
    "Content": ["Текст из параграфа", "Текст из элемента списка"],
    "links": ["https://example.com/link1", "https://example.com/link2"],
    "Child elements": [
        {
            "title": "Заголовок дочерней страницы",
            "publish_time": null,
            "source_url": "https://example.com/link1",
            "Content": ["Текст из параграфа на дочерней странице"],
            "links": ["https://example.com/link3"],
            "Child elements": []
        }
    ]
}
```

## Примечания

- Скрапер автоматически использует Playwright, если первоначальный запрос не смог получить контент, что полезно для страниц, которые используют JavaScript для отображения контента.
- PDF-файлы, ссылки на которые найдены на странице, будут загружены в директорию `pdf`.
- Убедитесь, что директории `jsons` и `pdf` существуют перед запуском скрипта, или измените код для их автоматического создания.