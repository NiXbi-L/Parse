# Инструкция по использованию парсеров

Этот проект предоставляет инструменты для парсинга веб-страниц с использованием различных подходов. Основные скрипты,
которые можно запускать: **`Basic_parser.py`**, **`Dynamic_parser.py`** и **`Run_script_in_txt.py`**. Каждый из них
предназначен для решения конкретных задач, связанных с парсингом веб-страниц.

---

## **Содержание**

1. [Установка и настройка](#установка-и-настройка)
    - [Установка зависимостей](#установка-зависимостей)
    - [Установка Playwright](#установка-playwright)
    - [Настройка путей к Chrome](#настройка-путей-к-chrome)
2. [Основные скрипты](#основные-скрипты)
    - [Basic_parser.py](#basic_parserpy)
    - [Dynamic_parser.py](#dynamic_parserpy)
    - [Run_script_in_txt.py](#run_script_in_txtpy)
    - [Как добавить прокси](#как-добавить-прокси)
3. [Примеры использования](#примеры-использования)
4. [Рекомендации](#рекомендации)

---

## **Установка и настройка**

### **Установка зависимостей**

Для работы проекта требуется установить несколько Python-библиотек. Вы можете установить их с помощью `pip`.

### Шаги:

1. Убедитесь, что у вас установлен Python версии 3.7 или выше.
2. Создайте виртуальное окружение (рекомендуется):
   ```bash
   python -m venv venv
   ```
3. Активируйте виртуальное окружение:
    - На Windows:
      ```bash
      venv\Scripts\activate
      ```
    - На macOS/Linux:
      ```bash
      source venv/bin/activate
      ```
4. Установите зависимости из файла `requirements.txt`:
   ```bash
   pip install -r requirements.txt
   ```

---

### **Установка Playwright**

Playwright используется для эмуляции браузера. После установки зависимостей необходимо установить браузеры, которые
будут использоваться Playwright.

### Шаги:

1. Установите браузеры с помощью команды:
   ```bash
   playwright install
   ```
   Эта команда установит браузеры (Chromium, Firefox, WebKit), которые будут использоваться для парсинга.

2. Убедитесь, что Playwright установлен корректно:
   ```bash
   playwright --version
   ```

---

### **Настройка путей к Chrome**

Для работы с Selenium необходимо указать пути к браузеру. Это делается в файле **`config.py`**.

### Шаги:

1. Создайте файл **`config.py`** в корневой директории проекта, если его нет.
2. Добавьте в него следующие строки:
   ```python
   chrome_path = "путь_к_chrome"              # Укажите путь к исполняемому файлу Chrome
   ```
3. Убедитесь, что пути указаны корректно и файлы существуют.
   [Используемая версия chrome](https://disk.yandex.ru/d/olB43YjmQOlbxg)

---

## **Основные скрипты**

### **Basic_parser.py**

Этот скрипт является основным инструментом для парсинга веб-страниц. Он поддерживает два режима работы:

- **Стандартный режим** (рекурсивный парсинг с глубиной 3).
- **Режим url_pool** (парсинг одной страницы или нескольких страниц из файла).

#### Параметры:

- **`url`**: Обязательный параметр в стандартном режиме. URL-адрес страницы для парсинга.
- **`mode`**: Режим работы. Возможные значения:
    - `standart` — стандартный режим (рекурсивный парсинг с глубиной 3).
    - `url_pool` — режим работы с пулом URL-адресов.
- **`load_type`**: Тип загрузки страницы. Возможные значения:
    - `auto` — автоматический выбор между запросом и браузером.
    - `request` — использование HTTP-запросов.
    - `browser` — использование браузера (Selenium или Playwright). **Каждая ссылка будет открываться с эмуляцией
      браузера.**
- **`proxy`**: Использование прокси. Возможные значения:
    - `True` — использовать прокси.
    - `False` — не использовать прокси.
- **`anti_bot`**: Использование обхода анти-бот системы. Возможные значения:
    - `True` — включить.
    - `False` — отключить.
- **`saving_period`**: Период сохранения результатов в секундах (по умолчанию `1`) испльзуется в стандартном режиме.
- **`chunk_size`**: Размер чанка (количество URL-адресов, обрабатываемых за один раз, по умолчанию `10`).
- **`url_pool`**: Обязательный параметр при работе с пулом адресов. Имя файла с пулом URL-адресов (по
  умолчанию `links.txt`).

---

### **Dynamic_parser.py**

Этот скрипт предназначен для парсинга страниц с **динамической загрузкой контента через JavaScript**. Он эмулирует
поведение пользователя в браузере, выполняя клики по элементам (например, кнопкам), которые могут не содержать прямых
ссылок, а вместо этого используют JavaScript для обработки кликов.

#### Когда использовать:

- На странице нет прямых ссылок, а вместо этого используется JavaScript для обработки кликов.
- Необходимо эмулировать поведение пользователя (клики, прокрутка и т.д.).

#### Параметры:

- **`url`**: Обязательный параметр. URL-адрес страницы для парсинга. (указывать первым параметром без `url=`)
- **`selector`**: Селектор элементов, на которые нужно кликать (по умолчанию `a`).
- **`by`**: Тип селектора (по умолчанию `TAG_NAME`).
- **`max_clicks`**: Максимальное количество кликов (по умолчанию `10`).
- **`html_to_json`**: Конвертировать HTML в JSON. Возможные значения:
    - `True` — включить конвертацию. После завершения работы браузера обработает все страницы и создать json файл с
      данными в папке указаной в параметре `html_output_folder`
    - `False` — отключить конвертацию.
- **`proxy`**: Использование прокси. Возможные значения:
    - `True` — использовать прокси.
    - `False` — не использовать прокси.
- **`referer`**: Референсная страница (по умолчанию `None`).

---

### **Run_script_in_txt.py**

Этот скрипт позволяет запускать несколько команд из текстового файла параллельно. Он просто выполняет команды, указанные
в файле, используя **`subprocess`**. Это полезно для массового запуска других скриптов (например, **`Dynamic_parser.py`
**) с разными аргументами.

#### Как это работает:

- Скрипт читает аргументы из текстового файла.
- Каждая строка файла должна содержать аргументы, которые нужно передать при запуске скрипта через `python` в терминале.
- Скрипт выполняет команды параллельно с использованием **`ThreadPoolExecutor`**.

#### Параметры:

- **`file_path`**: Обязательный параметр. Путь к файлу с командами для запуска.

#### Пример использования:

1. Создайте файл `commands.txt` с командами для запуска, например:
   ```
   Dynamic_parser.py https://example1.com selector=button by=By.TAG_NAME max_clicks=10
   Basic_parser.py load_type=browser anti_bot=True url_pool=in.txt mode=url_pool
   ```

2. Запустите скрипт:
   ```bash
   python Run_script_in_txt.py commands.txt
   ```

---

## **Как добавить прокси**

Прокси добавляются через файл **`proxy_pool.txt`**. Каждая строка в файле должна быть в формате:

```
<A or NA> https://<proxy_address>:<proxy_port> <login> <password>
```

- **`A`** — прокси с авторизацией.
- **`NA`** — прокси без авторизации.

#### Пример файла **`proxy_pool.txt`**:

```
A https://proxy1.example.com:8080 user1 password1
NA https://proxy2.example.com:8080
```

#### Как использовать прокси:

- В **`Basic_parser.py`** и **`Dynamic_parser.py`** укажите параметр `proxy=True`.
- Скрипт автоматически выберет прокси из файла **`proxy_pool.txt`**.

---

## **Примеры использования**

### 1. Парсинг одной страницы с рекурсивным обходом ссылок:

```bash
python Basic_parser.py url=https://example.com
```

### 2. Парсинг нескольких страниц из файла (режим url_pool):

```bash
python Basic_parser.py mode=url_pool url_pool=links.txt
```

### 3. Динамический парсинг с кликами по элементам (кнопки без ссылок):

```bash
python Dynamic_parser.py https://example.com
```

### 4. Массовый запуск команд из файла:

```bash
python Run_script_in_txt.py commands.txt
```

---

## **Рекомендации**

1. **Прокси**: Если вы парсите большое количество страниц, рекомендуется использовать прокси, чтобы избежать блокировки.
   Прокси можно указать в параметре `proxy=True`.
2. **Анти-бот системы**: Если сайт использует анти-бот системы, включите параметр `anti_bot=True` в **`Basic_parser.py`
   **.
3. **Параллельное выполнение**: Для ускорения процесса парсинга используйте **`Run_script_in_txt.py`** для параллельного
   выполнения задач.
4. **Динамический парсинг**: Если на странице нет прямых ссылок, а вместо этого используется JavaScript для обработки
   кликов, используйте **`Dynamic_parser.py`**.